{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Zero-Shot Learning and Supervised Learning for Spam Detection: A Study Using GPT-4 and LSTM Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the realm of Machine Learning and Natural Language Processing (NLP),\n",
    "various approaches exist to solve classification problems. Three\n",
    "commonly used methods are zero-shot learning, few-shot learning, and\n",
    "traditional supervised learning. In this analysis, we aim to compare\n",
    "these approaches, particularly in the context of a text classification\n",
    "problem.\n",
    "\n",
    "### Dataset and Classification Problem\n",
    "\n",
    "Our task revolves around the SMS Spam Collection Dataset, a public set\n",
    "of SMS labeled messages collected for mobile phone spam research. It\n",
    "includes a collection of more than 5,000 SMS messages, which have been\n",
    "manually labeled as either 'spam' or 'ham' (a term used to denote a\n",
    "non-spam message). The aim is to create models that can accurately\n",
    "classify new, unseen messages into these categories.\n",
    "\n",
    "> **Spam Classification Dataset:** The UCI Machine Learning Repository\n",
    "contains a SMS Spam Collection dataset that can be used for binary text\n",
    "classification: spam or ham (non-spam). The dataset is available\n",
    "[here](https://archive.ics.uci.edu/dataset/228/sms+spam+collection).\n",
    "\n",
    "\n",
    "### Issue with Imbalanced Data\n",
    "\n",
    "One significant aspect of this dataset, and many real-world datasets, is\n",
    "class imbalance. That is, the number of 'ham' messages significantly\n",
    "outweighs the number of 'spam' messages. This imbalance can present\n",
    "challenges in model training, as models may become biased towards\n",
    "predicting the majority class. In our case, a model might lean towards\n",
    "predicting 'ham' more often as it could still achieve a seemingly high\n",
    "accuracy that way. We will address this issue and present strategies for\n",
    "handling such class imbalances in our analysis.\n",
    "\n",
    "### Model Assessment Metrics and Evaluation\n",
    "\n",
    "To evaluate the performance of our models, we use three key metrics:\n",
    "Precision, Recall, and F1 Score. Precision measures the proportion of\n",
    "true positive predictions among all positive predictions, while Recall\n",
    "(also known as Sensitivity) measures the proportion of true positives\n",
    "that were correctly identified. The F1 Score is the harmonic mean of\n",
    "Precision and Recall and gives us a single metric that takes both false\n",
    "positives and false negatives into account.\n",
    "\n",
    "Traditionally, the Area Under the Curve (AUC) is often used as an\n",
    "evaluation metric, which depicts the model's performance across all\n",
    "classification thresholds. However, since we are using the OpenAI API\n",
    "for zero-shot and few-shot learning, and it does not provide the\n",
    "probability scores needed to compute the AUC, we will not use the AUC in\n",
    "this analysis. This limitation does not impact the efficacy of our\n",
    "comparison as Precision, Recall, and F1 Score offer robust measures to\n",
    "evaluate and compare the performance of our models.\n",
    "\n",
    "With the dataset, problem, challenges, and evaluation metrics defined,\n",
    "our aim is to compare the efficacy of zero-shot learning, few-shot\n",
    "learning, and traditional supervised learning techniques in solving this\n",
    "text classification problem. This comparison will provide insights into\n",
    "the strengths and weaknesses of each approach and guide us towards the\n",
    "most suitable method for this particular task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot In-Context Learning Using GPT-4 Model\n",
    "\n",
    "In the realm of machine learning, in-context learning refers to a method\n",
    "where a model leverages contextual information to generate responses or\n",
    "predictions. In the case of GPT-4, a state-of-the-art transformer-based\n",
    "language model developed by OpenAI, it uses a context window to inform\n",
    "its output based on provided prompts.\n",
    "\n",
    "In our scenario, we employ what is known as zero-shot learning in\n",
    "conjunction with in-context learning. Zero-shot learning is a type of\n",
    "machine learning where the model is asked to make predictions on data\n",
    "categories it has not explicitly seen during training. In other words,\n",
    "the model uses the generalized understanding it has developed during its\n",
    "pre-training phase to make predictions on unseen data. It is an\n",
    "appealing approach, especially in situations where labelled training\n",
    "data for specific tasks might be scarce or unavailable.\n",
    "\n",
    "In the context of our task, a text classification problem involving\n",
    "categorizing SMS messages as 'spam' or 'ham', the prompt for zero-shot\n",
    "learning using GPT-4 takes the following general structure:\n",
    "\n",
    "```text\n",
    "    prompt = (\n",
    "        \"Question: Given the following content, is it of type A or type B?\\n\"\n",
    "        f\"Content: {content}\\n\"\n",
    "        \"Answer Choices: (A) Type A, (B) Type B.\"\n",
    "    )\n",
    "```\n",
    "\n",
    "In our case, 'Type A' corresponds to 'spam' and 'Type B' corresponds to\n",
    "'ham', and `{content}` represents the SMS message we want the model to\n",
    "classify.\n",
    "\n",
    "One challenge we faced when employing this approach was the class\n",
    "imbalance in our dataset. In our dataset, 'ham' messages significantly\n",
    "outnumber 'spam' messages. To give an idea of the imbalance,\n",
    "approximately 87% of the messages are 'ham', leaving only about 13% as\n",
    "'spam'. Such an imbalance can lead to a bias in model predictions, with\n",
    "the model favoring the majority class, in this case, 'ham'.\n",
    "\n",
    "To address this issue, we utilized a balanced sample for model\n",
    "assessment. This was achieved by randomly sampling an equal number of\n",
    "'spam' and 'ham' messages, ensuring equal representation of both classes\n",
    "in our test set.\n",
    "\n",
    "The performance of zero-shot in-context learning with GPT-4 was\n",
    "evaluated using Precision, Recall, and F1 Score. Each metric provides\n",
    "insights into the model's performance considering both true positives\n",
    "and negatives, and false positives and negatives. Despite the OpenAI API\n",
    "limitations preventing us from calculating the AUC, these metrics\n",
    "provide a comprehensive evaluation of the effectiveness of the zero-shot\n",
    "in-context learning approach.\n",
    "\n",
    "In conclusion, zero-shot in-context learning with GPT-4 offers an\n",
    "exciting approach to our text classification task, demonstrating\n",
    "versatility in handling class imbalances, and effectiveness in\n",
    "generalizing without explicit task-related training. However, as we will\n",
    "explore in the following sections, other learning methods can also be\n",
    "applied and compared to this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6   ham  Even my brother is not like to speak with me. ...\n",
      "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8  spam  WINNER!! As a valued network customer you have...\n",
      "9  spam  Had your mobile 11 months or more? U R entitle...\n"
     ]
    }
   ],
   "source": [
    "# URL of the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
    "\n",
    "# Send a HTTP request to the URL of the zipfile\n",
    "r = requests.get(url)\n",
    "\n",
    "# Create a zipfile object from the content of the HTTP response\n",
    "z = zipfile.ZipFile(BytesIO(r.content))\n",
    "\n",
    "# Extract the content of the zipfile\n",
    "z.extractall()\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(\"SMSSpamCollection\", sep=\"\\t\", names=[\"label\", \"message\"])\n",
    "\n",
    "# Print the first few rows to check if the data has been read correctly\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"Question\": \"Given the following email content, is the email spam or not spam?\",\n",
    "            \"Email Content\": \"Dear user, you have won a million dollars! Click here to claim your prize.\",\n",
    "            \"Answer Choices\": \"(A) Spam, (B) Not Spam.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 1: HMV BONUS SPECIAL 500 pounds of genuine HMV vouchers to be won. Just answer 4 easy questions. Play Now! Send HMV to 86688 More info:www.100percent-real.com\n",
      "Response: (a) spam\n",
      "Message 2: EASTENDERS TV Quiz. What FLOWER does DOT compare herself to? D= VIOLET E= TULIP F= LILY txt D E or F to 84025 NOW 4 chance 2 WIN £100 Cash WKENT/150P16+\n",
      "Response: (a) spam\n",
      "Message 3: Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged\n",
      "Response: (a) spam\n",
      "Message 4: Shall i come to get pickle\n",
      "Response: (b) ham\n",
      "Message 5: That's the trouble with classes that go well - you're due a dodgey one … Expecting mine tomo! See you for recovery, same time, same place \n",
      "Response: (b) ham\n",
      "Message 6: Going thru a very different feeling.wavering decisions and coping up with the same is the same individual.time will heal everything i believe.\n",
      "Response: (b) ham\n",
      "Message 7: Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?\n",
      "Response: (a) spam\n",
      "Message 8: PRIVATE! Your 2003 Account Statement for shows 800 un-redeemed S.I.M. points. Call 08715203685 Identifier Code:4xx26 Expires 13/10/04\n",
      "Response: (a) spam\n",
      "Message 9: 100 dating service cal;l 09064012103 box334sk38ch\n",
      "Response: (a) spam\n",
      "Message 10: I'm already back home so no probably not\n",
      "Response: (b) ham\n",
      "Message 11: I know she called me\n",
      "Response: (b) ham\n",
      "Message 12: Natalie (20/F) is inviting you to be her friend. Reply YES-165 or NO-165 See her: www.SMS.ac/u/natalie2k9 STOP? Send STOP FRND to 62468\n",
      "Response: (a) spam\n",
      "Message 13: December only! Had your mobile 11mths+? You are entitled to update to the latest colour camera mobile for Free! Call The Mobile Update Co FREE on 08002986906\n",
      "Response: (a) spam\n",
      "Message 14: Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "Response: (a) spam\n",
      "Message 15: thanks for the temales it was wonderful. Thank. Have a great week.\n",
      "Response: (b) ham\n",
      "Message 16: So how's scotland. Hope you are not over showing your JJC tendencies. Take care. Live the dream\n",
      "Response: (b) ham\n",
      "Message 17: HARD BUT TRUE: How much you show &amp;  express your love to someone....that much it will hurt when they leave you or you get seperated...!鈥┾??〨ud evening...\n",
      "Response: (b) ham\n",
      "Message 18: You have WON a guaranteed £1000 cash or a £2000 prize. To claim yr prize call our customer service representative on 08714712394 between 10am-7pm\n",
      "Response: (a) spam\n",
      "Message 19: Dear Sir,Salam Alaikkum.Pride and Pleasure meeting you today at the Tea Shop.We are pleased to send you our contact number at Qatar.Rakhesh an Indian.Pls save our Number.Respectful Regards.\n",
      "Response: (b) ham\n",
      "Message 20: You are now unsubscribed all services. Get tons of sexy babes or hunks straight to your phone! go to http://gotbabes.co.uk. No subscriptions.\n",
      "Response: (a) spam\n",
      "Message 21: You can donate £2.50 to UNICEF's Asian Tsunami disaster support fund by texting DONATE to 864233. £2.50 will be added to your next bill\n",
      "Response: (b) ham\n",
      "Message 22: You are a winner you have been specially selected to receive £1000 cash or a £2000 award. Speak to a live operator to claim call 087147123779am-7pm. Cost 10p\n",
      "Response: (a) spam\n",
      "Message 23: Phony £350 award - Todays Voda numbers ending XXXX are selected to receive a £350 award. If you have a match please call 08712300220 quoting claim code 3100 standard rates app\n",
      "Response: (a) spam\n",
      "Message 24: Loan for any purpose £500 - £75,000. Homeowners + Tenants welcome. Have you been previously refused? We can still help. Call Free 0800 1956669 or text back 'help'\n",
      "Response: (a) spam\n",
      "Message 25: We tried to call you re your reply to our sms for a video mobile 750 mins UNLIMITED TEXT free camcorder Reply or call now 08000930705 Del Thurs\n",
      "Response: (a) spam\n",
      "Message 26: Nan sonathaya soladha. Why boss?\n",
      "Response: (b) ham\n",
      "Message 27: Do you want a New Nokia 3510i colour phone DeliveredTomorrow? With 300 free minutes to any mobile + 100 free texts + Free Camcorder reply or call 08000930705.\n",
      "Response: (a) spam\n",
      "Message 28: FREE entry into our £250 weekly competition just text the word WIN to 80086 NOW. 18 T&C www.txttowin.co.uk\n",
      "Response: (a) spam\n",
      "Message 29: Which channel:-):-):):-).\n",
      "Response: (b) ham\n",
      "Message 30: important information 4 orange user 0789xxxxxxx. today is your lucky day!2find out why log onto http://www.urawinner.com THERE'S A FANTASTIC SURPRISE AWAITING YOU!\n",
      "Response: (a) spam\n",
      "Message 31: 74355 XMAS iscoming & ur awarded either £500 CD gift vouchers & free entry 2 r £100 weekly draw txt MUSIC to 87066 TnC\n",
      "Response: (a) spam\n",
      "Message 32: It‘s £6 to get in, is that ok?\n",
      "Response: (b) ham\n",
      "Message 33: Thank you so much. When we skyped wit kz and sura, we didnt get the pleasure of your company. Hope you are good. We've given you ultimatum oh! We are countin down to aburo. Enjoy!\n",
      "Response: (b) ham\n",
      "Message 34: I've got ten bucks, jay is being noncomittal\n",
      "Response: (b) ham\n",
      "Message 35: Hey pple...$700 or $900 for 5 nights...Excellent location wif breakfast hamper!!!\n",
      "Response: (a) spam\n",
      "Message 36: YOU HAVE WON! As a valued Vodafone customer our computer has picked YOU to win a £150 prize. To collect is easy. Just call 09061743386 \n",
      "Response: (a) spam\n",
      "Message 37: Here got ur favorite oyster... N got my favorite sashimi... Ok lar i dun say already... Wait ur stomach start rumbling...\n",
      "Response: (b) ham\n",
      "Message 38: Fancy a shag? I do.Interested? sextextuk.com txt XXUK SUZY to 69876. Txts cost 1.50 per msg. TnCs on website. X\n",
      "Response: (a) spam\n",
      "Message 39: Congratulations ur awarded either £500 of CD gift vouchers & Free entry 2 our £100 weekly draw txt MUSIC to 87066 TnCs www.Ldew.com1win150ppmx3age16\n",
      "Response: (a) spam\n",
      "Message 40: Po de :-):):-):-):-). No need job aha.\n",
      "Response: (a) spam\n",
      "Message 41: I know you are serving. I mean what are you doing now.\n",
      "Response: (b) ham\n",
      "Message 42:  what number do u live at? Is it 11?\n",
      "Response: (a) spam\n",
      "Message 43: Okie... Thanx...\n",
      "Response: (b) ham\n",
      "Message 44: Hack Chat. Get backdoor entry into 121 chat rooms at a fraction of the cost. Reply NEO69 or call 09050280520, to subscribe 25p pm. DPS, Bcm box 8027 Ldn, wc1n3xx\n",
      "Response: (a) spam\n",
      "Message 45: Want 2 get laid tonight? Want real Dogging locations sent direct 2 ur mob? Join the UK's largest Dogging Network bt Txting GRAVEL to 69888! Nt. ec2a. 31p.msg@150p\n",
      "Response: (a) spam\n",
      "Message 46: lyricalladie(21/F) is inviting you to be her friend. Reply YES-910 or NO-910. See her: www.SMS.ac/u/hmmross STOP? Send STOP FRND to 62468\n",
      "Response: (a) spam\n",
      "Message 47: 5 nights...We nt staying at port step liao...Too ex\n",
      "Response: (b) ham\n",
      "Message 48: 1st wk FREE! Gr8 tones str8 2 u each wk. Txt NOKIA ON to 8007 for Classic Nokia tones or HIT ON to 8007 for Polys. Nokia/150p Poly/200p 16+\n",
      "Response: (a) spam\n",
      "Message 49: I'm meeting Darren...\n",
      "Response: (b) ham\n",
      "Message 50: Welp apparently he retired\n",
      "Response: (b) ham\n",
      "Message 51: For your chance to WIN a FREE Bluetooth Headset then simply reply back with \"ADP\"\n",
      "Response: (a) spam\n",
      "Message 52: Ü collecting ur laptop then going to configure da settings izzit?\n",
      "Response: (b) ham\n",
      "Message 53: Ok lor. Anyway i thk we cant get tickets now cos like quite late already. U wan 2 go look 4 ur frens a not? Darren is wif them now...\n",
      "Response: (b) ham\n",
      "Message 54: PRIVATE! Your 2003 Account Statement for shows 800 un-redeemed S. I. M. points. Call 08715203652 Identifier Code: 42810 Expires 29/10/0\n",
      "Response: (a) spam\n",
      "Message 55: URGENT We are trying to contact you Last weekends draw shows u have won a £1000 prize GUARANTEED Call 09064017295 Claim code K52 Valid 12hrs 150p pm\n",
      "Response: (a) spam\n",
      "Message 56: Eh den sat u book e kb liao huh...\n",
      "Response: (b) ham\n",
      "Message 57: Ok no prob... I'll come after lunch then...\n",
      "Response: (b) ham\n",
      "Message 58: The gas station is like a block away from my house, you'll drive right by it since armenia ends at swann and you have to take howard\n",
      "Response: (b) ham\n",
      "Message 59: Howz pain?hope u r fine..\n",
      "Response: (b) ham\n",
      "Message 60: 26th OF JULY\n",
      "Response: the content provided is too limited to make a definite decision. please provide more information.\n",
      "Message 61: Thats cool! Sometimes slow and gentle. Sonetimes rough and hard :)\n",
      "Response: (b) ham\n",
      "Message 62: YES! The only place in town to meet exciting adult singles is now in the UK. Txt CHAT to 86688 now! 150p/Msg.\n",
      "Response: (a) spam\n",
      "Message 63: HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national rate call\n",
      "Response: (a) spam\n",
      "Message 64: Urgent Urgent! We have 800 FREE flights to Europe to give away, call B4 10th Sept & take a friend 4 FREE. Call now to claim on 09050000555. BA128NNFWFLY150ppm\n",
      "Response: (a) spam\n",
      "Message 65: Todays Vodafone numbers ending with 4882 are selected to a receive a £350 award. If your number matches call 09064019014 to receive your £350 award.\n",
      "Response: (a) spam\n",
      "Message 66: You have won ?1,000 cash or a ?2,000 prize! To claim, call09050000327\n",
      "Response: (a) spam\n",
      "Message 67: But i'll b going 2 sch on mon. My sis need 2 take smth.\n",
      "Response: (b) ham\n",
      "Message 68: Do you know why god created gap between your fingers..? So that, One who is made for you comes &amp; fills those gaps by holding your hand with LOVE..!\n",
      "Response: (b) ham\n",
      "Message 69: 4mths half price Orange line rental & latest camera phones 4 FREE. Had your phone 11mths+? Call MobilesDirect free on 08000938767 to update now! or2stoptxt T&Cs\n",
      "Response: (a) spam\n",
      "Message 70: Hello. We need some posh birds and chaps to user trial prods for champneys. Can i put you down? I need your address and dob asap. Ta r\n",
      "Response: (a) spam\n",
      "Message 71: FREE RING TONE just text \"POLYS\" to 87131. Then every week get a new tone. 0870737910216yrs only £1.50/wk.\n",
      "Response: (a) spam\n",
      "Message 72: Send a logo 2 ur lover - 2 names joined by a heart. Txt LOVE NAME1 NAME2 MOBNO eg LOVE ADAM EVE 07123456789 to 87077 Yahoo! POBox36504W45WQ TxtNO 4 no ads 150p\n",
      "Response: (a) spam\n",
      "Message 73: If i start sending blackberry torch to nigeria will you find buyer for me?like 4a month. And tell dad not to buy bb from anyone oh.\n",
      "Response: (b) ham\n",
      "Message 74: I dont know ask to my brother. Nothing problem some thing that. Just i told .\n",
      "Response: (b) ham\n",
      "Message 75: Dear got train and seat mine lower seat\n",
      "Response: (a) spam\n",
      "Message 76: Hmm, too many of them unfortunately... Pics obviously arent hot cakes. Its kinda fun tho\n",
      "Response: (b) ham\n",
      "Message 77: Your 2004 account for 07XXXXXXXXX shows 786 unredeemed points. To claim call 08719181259 Identifier code: XXXXX Expires 26.03.05\n",
      "Response: (a) spam\n",
      "Message 78: I‘ve got some salt, you can rub it in my open wounds if you like!\n",
      "Response: (b) ham\n",
      "Message 79: Sunshine Quiz Wkly Q! Win a top Sony DVD player if u know which country the Algarve is in? Txt ansr to 82277. £1.50 SP:Tyrone\n",
      "Response: (a) spam\n",
      "Message 80: Bring it if you got it\n",
      "Response: (b) ham\n",
      "Message 81: When should I come over?\n",
      "Response: (b) ham\n",
      "Message 82: LookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\n",
      "Response: (b) ham\n",
      "Message 83: Spook up your mob with a Halloween collection of a logo & pic message plus a free eerie tone, txt CARD SPOOK to 8007 zed 08701417012150p per logo/pic\n",
      "Response: (a) spam\n",
      "Message 84: Princess, i like to make love  &lt;#&gt;  times per night. Hope thats not a problem!\n",
      "Response: (b) ham\n",
      "Message 85: K...k:)why cant you come here and search job:)\n",
      "Response: (b) ham\n",
      "Message 86: PRIVATE! Your 2004 Account Statement for 07742676969 shows 786 unredeemed Bonus Points. To claim call 08719180248 Identifier Code: 45239 Expires\n",
      "Response: (a) spam\n",
      "Message 87: FREE for 1st week! No1 Nokia tone 4 ur mob every week just txt NOKIA to 8007 Get txting and tell ur mates www.getzed.co.uk POBox 36504 W45WQ norm150p/tone 16+\n",
      "Response: (a) spam\n",
      "Message 88: Meet after lunch la...\n",
      "Response: (b) ham\n",
      "Message 89: You best watch what you say cause I get drunk as a motherfucker\n",
      "Response: answer: (b) ham.\n",
      "Message 90: Thanks 4 your continued support Your question this week will enter u in2 our draw 4 £100 cash. Name the NEW US President? txt ans to 80082\n",
      "Response: (a) spam\n",
      "Message 91: 4mths half price Orange line rental & latest camera phones 4 FREE. Had your phone 11mths ? Call MobilesDirect free on 08000938767 to update now! or2stoptxt\n",
      "Response: (a) spam\n",
      "Message 92: Hungry gay guys feeling hungry and up 4 it, now. Call 08718730555 just 10p/min. To stop texts call 08712460324 (10p/min)\n",
      "Response: (a) spam\n",
      "Message 93: Hello! Good week? Fancy a drink or something later?\n",
      "Response: (b) ham\n",
      "Message 94: Please tell me you have some of that special stock you were talking about\n",
      "Response: (b) ham\n",
      "Message 95: Its a site to simulate the test. It just gives you very tough questions to test your readiness.\n",
      "Response: (b) ham\n",
      "Message 96: Hi. Hope you had a good day. Have a better night.\n",
      "Response: (b) ham\n",
      "Message 97: Can you do online transaction?\n",
      "Response: (a) spam\n",
      "Message 98: O. Guess they both got screwd\n",
      "Response: (b) ham\n",
      "Message 99: Hi, Mobile no.  &lt;#&gt;  has added you in their contact list on www.fullonsms.com It s a great place to send free sms to people For more visit fullonsms.com\n",
      "Response: (a) spam\n",
      "Message 100: Just send a text. We'll skype later.\n",
      "Response: (b) ham\n",
      "Message 101: FreeMsg Hi baby wow just got a new cam moby. Wanna C a hot pic? or Fancy a chat?Im w8in 4uTxt / rply CHAT to 82242 Hlp 08712317606 Msg150p 2rcv\n",
      "Response: (a) spam\n",
      "Message 102: Urgent Ur £500 guaranteed award is still unclaimed! Call 09066368327 NOW closingdate04/09/02 claimcode M39M51 £1.50pmmorefrommobile2Bremoved-MobyPOBox734LS27YF\n",
      "Response: (a) spam\n",
      "Message 103: <Forwarded from 21870000>Hi - this is your Mailbox Messaging SMS alert. You have 4 messages. You have 21 matches. Please call back on 09056242159 to retrieve your messages and matches\n",
      "Response: (a) spam\n",
      "Message 104: Who were those people ? Were you in a tour ? I thought you were doing that sofa thing you sent me ? Your curious sugar\n",
      "Response: (b) ham\n",
      "Message 105: Free msg. Sorry, a service you ordered from 81303 could not be delivered as you do not have sufficient credit. Please top up to receive the service.\n",
      "Response: (a) spam\n",
      "Message 106: Our brand new mobile music service is now live. The free music player will arrive shortly. Just install on your phone to browse content from the top artists.\n",
      "Response: (a) spam\n",
      "Message 107: Ur cash-balance is currently 500 pounds - to maximize ur cash-in now send CASH to 86688 only 150p/msg. CC: 08718720201 PO BOX 114/14 TCR/W1\n",
      "Response: (a) spam\n",
      "Message 108: When did you get to the library\n",
      "Response: (b) ham\n",
      "Message 109: Dear Voucher Holder, To claim this weeks offer, at you PC please go to http://www.e-tlp.co.uk/reward. Ts&Cs apply.\n",
      "Response: (a) spam\n",
      "Message 110: No, its true..k,Do u knw dis no. &lt;#&gt; ?\n",
      "Response: (a) spam\n",
      "Message 111: Marvel Mobile Play the official Ultimate Spider-man game (£4.50) on ur mobile right now. Text SPIDER to 83338 for the game & we ll send u a FREE 8Ball wallpaper\n",
      "Response: (a) spam\n",
      "Message 112: Otherwise had part time job na-tuition..\n",
      "Response: (b) ham\n",
      "Message 113: Last Chance! Claim ur £150 worth of discount vouchers today! Text SHOP to 85023 now! SavaMob, offers mobile! T Cs SavaMob POBOX84, M263UZ. £3.00 Sub. 16\n",
      "Response: (a) spam\n",
      "Message 114: Double Mins & Double Txt & 1/2 price Linerental on Latest Orange Bluetooth mobiles. Call MobileUpd8 for the very latest offers. 08000839402 or call2optout/LF56\n",
      "Response: (a) spam\n",
      "Message 115: Freemsg: 1-month unlimited free calls! Activate SmartCall Txt: CALL to No: 68866. Subscriptn3gbp/wk unlimited calls Help: 08448714184 Stop?txt stop landlineonly\n",
      "Response: (a) spam\n",
      "Message 116: Hahaha..use your brain dear\n",
      "Response: (b) ham\n",
      "Message 117: Goal! Arsenal 4 (Henry, 7 v Liverpool 2 Henry scores with a simple shot from 6 yards from a pass by Bergkamp to give Arsenal a 2 goal margin after 78 mins.\n",
      "Response: (b) ham\n",
      "Message 118: Aiya we discuss later lar... Pick ü up at 4 is it?\n",
      "Response: (b) ham\n",
      "Message 119: Urgent Please call 09066612661 from landline. £5000 cash or a luxury 4* Canary Islands Holiday await collection. T&Cs SAE award. 20M12AQ. 150ppm. 16+ “\n",
      "Response: (a) spam\n",
      "Message 120: WIN a year supply of CDs 4 a store of ur choice worth £500 & enter our £100 Weekly draw txt MUSIC to 87066 Ts&Cs www.Ldew.com.subs16+1win150ppmx3\n",
      "Response: (a) spam\n",
      "Message 121: <Forwarded from 88877>FREE entry into our £250 weekly comp just send the word ENTER to 88877 NOW. 18 T&C www.textcomp.com\n",
      "Response: (a) spam\n",
      "Message 122: URGENT! Your mobile No 07xxxxxxxxx won a £2,000 bonus caller prize on 02/06/03! this is the 2nd attempt to reach YOU! call 09066362231 ASAP! BOX97N7QP, 150PPM\n",
      "Response: (a) spam\n",
      "Message 123: I'm going 2 orchard now laready me reaching soon. U reaching?\n",
      "Response: (b) ham\n",
      "Message 124: I'm vivek:)i got call from your number.\n",
      "Response: (b) ham\n",
      "Message 125: Really good:)dhanush rocks once again:)\n",
      "Response: (b) ham\n",
      "Message 126: Gr8 new service - live sex video chat on your mob - see the sexiest dirtiest girls live on ur phone - 4 details text horny to 89070 to cancel send STOP to 89070\n",
      "Response: (a) spam\n",
      "Message 127: Sorry, was in the bathroom, sup\n",
      "Response: (b) ham\n",
      "Message 128: Hmmm:)how many players selected?\n",
      "Response: (b) ham\n",
      "Message 129: When are you guys leaving?\n",
      "Response: (b) ham\n",
      "Message 130: Ur balance is now £500. Ur next question is: Who sang 'Uptown Girl' in the 80's ? 2 answer txt ur ANSWER to 83600. Good luck!\n",
      "Response: (a) spam\n",
      "Message 131: Congratulations YOU'VE Won. You're a Winner in our August £1000 Prize Draw. Call 09066660100 NOW. Prize Code 2309.\n",
      "Response: (a) spam\n",
      "Message 132: URGENT This is our 2nd attempt to contact U. Your £900 prize from YESTERDAY is still awaiting collection. To claim CALL NOW 09061702893\n",
      "Response: (a) spam\n",
      "Message 133: Huh? 6 also cannot? Then only how many mistakes?\n",
      "Response: (b) ham\n",
      "Message 134: Ok enjoy . R u there in home.\n",
      "Response: (b) ham\n",
      "Message 135: No. Thank you. You've been wonderful\n",
      "Response: (b) ham\n",
      "Message 136: Todays Voda numbers ending 1225 are selected to receive a £50award. If you have a match please call 08712300220 quoting claim code 3100 standard rates app \n",
      "Response: (a) spam\n",
      "Message 137: I walked an hour 2 c u! doesnt that show I care y wont u believe im serious?\n",
      "Response: (b) ham\n",
      "Message 138: U have a Secret Admirer who is looking 2 make contact with U-find out who they R*reveal who thinks UR so special-call on 09065171142-stopsms-08718727870150ppm\n",
      "Response: (a) spam\n",
      "Message 139: Stupid.its not possible\n",
      "Response: (b) ham\n",
      "Message 140: K..u also dont msg or reply to his msg..\n",
      "Response: (b) ham\n",
      "Message 141: You're gonna have to be way more specific than that\n",
      "Response: (b) ham\n",
      "Message 142: I dont understand your message.\n",
      "Response: (b) ham\n",
      "Message 143: Haha I heard that, text me when you're around\n",
      "Response: (b) ham\n",
      "Message 144: Babes I think I got ur brolly I left it in English wil bring it in 2mrw 4 u luv Franxx\n",
      "Response: (b) ham\n",
      "Message 145: Got what it takes 2 take part in the WRC Rally in Oz? U can with Lucozade Energy! Text RALLY LE to 61200 (25p), see packs or lucozade.co.uk/wrc & itcould be u!\n",
      "Response: (a) spam\n",
      "Message 146: Do you want a New Nokia 3510i Colour Phone Delivered Tomorrow? With 200 FREE minutes to any mobile + 100 FREE text + FREE camcorder Reply or Call 08000930705\n",
      "Response: (a) spam\n",
      "Message 147: FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GBP/mnth inc 3hrs 16 stop?txtStop\n",
      "Response: (a) spam\n",
      "Message 148: How much you got for cleaning\n",
      "Response: (b) ham.\n",
      "Message 149: Realy sorry-i don't recognise this number and am now confused :) who r u please?! \n",
      "Response: (b) ham\n",
      "Message 150: Wanna get laid 2nite? Want real Dogging locations sent direct to ur mobile? Join the UK's largest Dogging Network. Txt PARK to 69696 now! Nyt. ec2a. 3lp £1.50/msg\n",
      "Response: (a) spam\n",
      "Message 151: For ur chance to win a £250 wkly shopping spree TXT: SHOP to 80878. T's&C's www.txt-2-shop.com custcare 08715705022, 1x150p/wk\n",
      "Response: (a) spam\n",
      "Message 152: PRIVATE! Your 2003 Account Statement for 07808247860 shows 800 un-redeemed S. I. M. points. Call 08719899229 Identifier Code: 40411 Expires 06/11/04\n",
      "Response: (a) spam\n",
      "Message 153: You won't believe it but it's true. It's Incredible Txts! Reply G now to learn truly amazing things that will blow your mind. From O2FWD only 18p/txt\n",
      "Response: (a) spam\n",
      "Message 154: URGENT, IMPORTANT INFORMATION FOR O2 USER. TODAY IS YOUR LUCKY DAY! 2 FIND OUT WHY LOG ONTO HTTP://WWW.URAWINNER.COM THERE IS A FANTASTIC SURPRISE AWAITING FOR YOU\n",
      "Response: (a) spam\n",
      "Message 155: You will be receiving this week's Triple Echo ringtone shortly. Enjoy it!\n",
      "Response: (a) spam\n",
      "Message 156: Thanks for your ringtone order, ref number R836. Your mobile will be charged £4.50. Should your tone not arrive please call customer services on 09065069154\n",
      "Response: (a) spam\n",
      "Message 157: somewhere out there beneath the pale moon light someone think in of u some where out there where dreams come true... goodnite &amp; sweet dreams\n",
      "Response: (b) ham\n",
      "Message 158: Double mins and txts 4 6months FREE Bluetooth on Orange. Available on Sony, Nokia Motorola phones. Call MobileUpd8 on 08000839402 or call2optout/N9DX\n",
      "Response: (a) spam\n",
      "Message 159: Hey i'm bored... So i'm thinking of u... So wat r u doing?\n",
      "Response: (b) ham\n",
      "Message 160: So why didnt you holla?\n",
      "Response: (b) ham\n",
      "Message 161: CHEERS U TEX MECAUSE U WEREBORED! YEAH OKDEN HUNNY R UIN WK SAT?SOUNDS LIKEYOUR HAVIN GR8FUN J! KEEP UPDAT COUNTINLOTS OF LOVEME XXXXX.\n",
      "Response: (a) spam\n",
      "Message 162: Ur TONEXS subscription has been renewed and you have been charged £4.50. You can choose 10 more polys this month. www.clubzed.co.uk *BILLING MSG*\n",
      "Response: (a) spam\n",
      "Message 163: Is she replying. Has boye changed his phone number\n",
      "Response: (b) ham\n",
      "Message 164: Yup\n",
      "Response: (b) ham\n",
      "Message 165: Mmmm ... Fuck ... Not fair ! You know my weaknesses ! *grins* *pushes you to your knee's* *exposes my belly and pulls your head to it* Don't forget ... I know yours too *wicked smile*\n",
      "Response: (b) ham\n",
      "Message 166: ringtoneking 84484\n",
      "Response: (a) spam\n",
      "Message 167: Ur cash-balance is currently 500 pounds - to maximize ur cash-in now send GO to 86688 only 150p/msg. CC: 08718720201 PO BOX 114/14 TCR/W1\n",
      "Response: (a) spam\n",
      "Message 168: Aight, I'll ask a few of my roommates\n",
      "Response: (b) ham\n",
      "Message 169: Thank you, winner notified by sms. Good Luck! No future marketing reply STOP to 84122 customer services 08450542832\n",
      "Response: (a) spam\n",
      "Message 170: **FREE MESSAGE**Thanks for using the Auction Subscription Service. 18 . 150p/MSGRCVD 2 Skip an Auction txt OUT. 2 Unsubscribe txt STOP CustomerCare 08718726270\n",
      "Response: (a) spam\n",
      "Message 171: Final Chance! Claim ur £150 worth of discount vouchers today! Text YES to 85023 now! SavaMob, member offers mobile! T Cs SavaMob POBOX84, M263UZ. £3.00 Subs 16\n",
      "Response: (a) spam\n",
      "Message 172: You are a winner U have been specially selected 2 receive £1000 cash or a 4* holiday (flights inc) speak to a live operator 2 claim 0871277810810\n",
      "Response: (a) spam\n",
      "Message 173: You have won a guaranteed 32000 award or maybe even £1000 cash to claim ur award call free on 0800 ..... (18+). Its a legitimat efreefone number wat do u think???\n",
      "Response: (a) spam\n",
      "Message 174: 18 days to Euro2004 kickoff! U will be kept informed of all the latest news and results daily. Unsubscribe send GET EURO STOP to 83222.\n",
      "Response: (a) spam\n",
      "Message 175: Me too. Mark is taking forever to pick up my prescription and the pain is coming back.\n",
      "Response: (b) ham\n",
      "Message 176: As in i want custom officer discount oh.\n",
      "Response: (b) ham\n",
      "Message 177: SMS AUCTION - A BRAND NEW Nokia 7250 is up 4 auction today! Auction is FREE 2 join & take part! Txt NOKIA to 86021 now!\n",
      "Response: (a) spam\n",
      "Message 178: December only! Had your mobile 11mths+? You are entitled to update to the latest colour camera mobile for Free! Call The Mobile Update Co FREE on 08002986906\n",
      "Response: (a) spam\n",
      "Message 179: FREE MESSAGE Activate your 500 FREE Text Messages by replying to this message with the word FREE For terms & conditions, visit www.07781482378.com\n",
      "Response: (a) spam\n",
      "Message 180: You have been specially selected to receive a 2000 pound award! Call 08712402050 BEFORE the lines close. Cost 10ppm. 16+. T&Cs apply. AG Promo\n",
      "Response: (a) spam\n",
      "Message 181: Beautiful Truth against Gravity.. Read carefully: \"Our heart feels light when someone is in it.. But it feels very heavy when someone leaves it..\" GOOD NIGHT\n",
      "Response: (b) ham\n",
      "Message 182: Its normally hot mail. Com you see!\n",
      "Response: (b) ham\n",
      "Message 183: Stupid auto correct on my phone\n",
      "Response: (b) ham\n",
      "Message 184: * Will be september by then!\n",
      "Response: (b) ham\n",
      "Message 185: Arun can u transfr me d amt\n",
      "Response: (b) ham\n",
      "Message 186: Yo, the game almost over? Want to go to walmart soon\n",
      "Response: (b) ham\n",
      "Message 187: URGENT!! Your 4* Costa Del Sol Holiday or £5000 await collection. Call 09050090044 Now toClaim. SAE, TC s, POBox334, Stockport, SK38xh, Cost£1.50/pm, Max10mins\n",
      "Response: (a) spam\n",
      "Message 188: Once free call me sir. I am waiting for you.\n",
      "Response: (b) ham\n",
      "Message 189: URGENT! We are trying to contact U Todays draw shows that you have won a £800 prize GUARANTEED. Call 09050000460 from land line. Claim J89. po box245c2150pm\n",
      "Response: (a) spam\n",
      "Message 190: Happy new years melody!\n",
      "Response: (b) ham\n",
      "Message 191: HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870..k\n",
      "Response: (a) spam\n",
      "Message 192: Yes... I trust u to buy new stuff ASAP so I can try it out\n",
      "Response: (b) ham\n",
      "Message 193: Why is that, princess? I bet the brothas are all chasing you!\n",
      "Response: (b) ham\n",
      "Message 194: excellent. I spent  &lt;#&gt;  years in the Air Force. Iraq and afghanistan. I am stable and honest. do you like traveling?\n",
      "Response: (b) ham\n",
      "Message 195: 44 7732584351, Do you want a New Nokia 3510i colour phone DeliveredTomorrow? With 300 free minutes to any mobile + 100 free texts + Free Camcorder reply or call 08000930705.\n",
      "Response: (a) spam\n",
      "Message 196: Jus finish watching tv... U?\n",
      "Response: (b) ham\n",
      "Message 197: I.ll always be there, even if its just in spirit. I.ll get a bb soon. Just trying to be sure i need it.\n",
      "Response: (b) ham\n",
      "Message 198: SMS SERVICES. for your inclusive text credits, pls goto www.comuk.net login= ***** unsubscribe with STOP. no extra charge. help:08700469649. PO BOX420. IP4 5WE\n",
      "Response: (a) spam\n",
      "Message 199: Hope youre not having too much fun without me!! see u tomorrow love jess x\n",
      "Response: (b) ham\n",
      "Message 200: we tried to contact you re your response to our offer of a new nokia fone and camcorder hit reply or call 08000930705 for delivery\n",
      "Response: (a) spam\n",
      "Precision: 0.92\n",
      "Recall: 0.97\n",
      "F1 Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Get the first 100 messages and labels\n",
    "# messages = df['message'][:100]\n",
    "# labels = df['label'][:100]\n",
    "# Randomly sample 100 messages and labels\n",
    "# sample = df.sample(n=200, random_state=1)\n",
    "# messages = sample['message']\n",
    "# labels = sample['label']\n",
    "\n",
    "# Separate the dataset into spam and ham\n",
    "spam_df = df[df[\"label\"] == \"spam\"]\n",
    "ham_df = df[df[\"label\"] == \"ham\"]\n",
    "\n",
    "# Sample 100 messages from each\n",
    "spam_sample = spam_df.sample(n=100, random_state=1)\n",
    "ham_sample = ham_df.sample(n=100, random_state=1)\n",
    "\n",
    "# Concatenate the samples to create a balanced sample of 200\n",
    "balanced_sample = pd.concat([spam_sample, ham_sample])\n",
    "\n",
    "# Shuffle the sample to ensure randomness\n",
    "balanced_sample = balanced_sample.sample(frac=1, random_state=1)\n",
    "\n",
    "# Balanced messages and labels\n",
    "messages = balanced_sample[\"message\"]\n",
    "labels = balanced_sample[\"label\"]\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i, (msg, true_label) in enumerate(zip(messages, labels)):\n",
    "    prompt = (\n",
    "        \"Question: Given the following email content, is the email spam or ham?\\n\"\n",
    "        f\"Email Content: {msg}\\n\"\n",
    "        \"Answer Choices: (A) spam, (B) ham.\"\n",
    "    )\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant capable of identifying spam emails.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(f\"Message {i+1}: {msg}\")\n",
    "    response = completion.choices[0].message[\"content\"].lower()\n",
    "    print(\"Response:\", response)\n",
    "\n",
    "    # Extract prediction from response\n",
    "    predicted_label = \"spam\" if \"spam\" in response else \"ham\"\n",
    "    predictions.append(predicted_label)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(labels, predictions, pos_label=\"spam\")\n",
    "recall = recall_score(labels, predictions, pos_label=\"spam\")\n",
    "f1 = f1_score(labels, predictions, pos_label=\"spam\")\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of Zero-Shot In-Context Learning with GPT-4\n",
    "\n",
    "The performance of the GPT-4 model for our SMS spam classification\n",
    "problem was evaluated using three metrics: precision, recall, and F1\n",
    "score. Here is a table summarizing the obtained values:\n",
    "\n",
    "|       | Precision | Recall | F1 Score |\n",
    "|-------|-----------|--------|----------|\n",
    "| GPT-4 | 0.92      | 0.97   | 0.95     |\n",
    "\n",
    "Let's interpret these results:\n",
    "\n",
    "1. **Precision:** Precision is a measure of the model's accuracy considering only the predicted positive instances. In the context of our problem, a precision of 0.92 means that when GPT-4 predicts a message to be 'spam', it is correct 92% of the time. This level of precision indicates a relatively low rate of false positive classifications (i.e., 'ham' messages incorrectly classified as 'spam').\n",
    "\n",
    "2. **Recall:** Recall, also known as sensitivity or true positive rate, measures the proportion of actual positives that are correctly identified. In our scenario, a recall of 0.97 means that the model identifies 97% of all actual 'spam' messages correctly. However, it also indicates a 3% rate of false negatives (i.e., 'spam' messages incorrectly classified as 'ham').\n",
    "\n",
    "3. **F1 Score:** The F1 score is the harmonic mean of precision and recall, and it gives a balanced measure of these two metrics. An F1 score of 0.95 indicates a balance between precision and recall, demonstrating the model's robustness in handling both false positives and false negatives.\n",
    "\n",
    "The performance of the GPT-4 model on this task is quite remarkable\n",
    "given it is a zero-shot learning scenario. However, we can further\n",
    "improve this performance, or at least attempt to, by employing other\n",
    "learning techniques, such as few-shot learning and supervised learning.\n",
    "The following sections will delve into these other approaches."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing In-Context Learning with Supervised Learning using LSTM\n",
    "\n",
    "In our analysis, we have employed two distinct methodologies for text\n",
    "classification, namely in-context learning using GPT-4 and a supervised\n",
    "learning approach using an LSTM model. Both of these methods have shown\n",
    "promising results, and now we aim to compare them and understand their\n",
    "differences and respective advantages.\n",
    "\n",
    "### In-Context Learning with GPT-4\n",
    "\n",
    "In the in-context learning scenario, we used OpenAI's GPT-4, a\n",
    "state-of-the-art language model that utilizes Transformer-based neural\n",
    "networks. For this task, we trained GPT-4 with a few examples of spam\n",
    "and ham email contents and asked the model to predict whether a new\n",
    "email is spam or ham based on the content. We used the responses from\n",
    "GPT-4 to generate classification labels and evaluated the performance\n",
    "using precision, recall, and F1 score. \n",
    "\n",
    "The use of GPT-4 simplifies the process since it does not require\n",
    "explicit feature engineering or manual training of a machine learning\n",
    "model. The downside, however, is that GPT-4 is a black-box model with\n",
    "limited interpretability and could be sensitive to the prompt design and\n",
    "wording, which could potentially affect the model's predictions.\n",
    "\n",
    "### Supervised Learning using LSTM\n",
    "\n",
    "On the other hand, we employed a Long Short-Term Memory (LSTM) model, a\n",
    "type of recurrent neural network, in a supervised learning context.\n",
    "LSTMs are particularly useful for sequence prediction problems as they\n",
    "can store past information, making them ideal for text classification\n",
    "tasks like ours.\n",
    "\n",
    "Our LSTM model was trained on preprocessed sequences of text from the\n",
    "emails and their corresponding labels (spam or ham). We used an\n",
    "Embedding layer for converting words to vectors, an LSTM layer for\n",
    "learning the sequences within the text, and a Dense layer for output. We\n",
    "then trained the model using the Adam optimizer and binary cross-entropy\n",
    "loss function, given the binary nature of our classification task.\n",
    "\n",
    "The LSTM model has shown high precision, recall, and F1 Score,\n",
    "demonstrating its effectiveness in text classification tasks. However,\n",
    "it's worth noting that building and training the LSTM model required\n",
    "more effort compared to using GPT-4, including preprocessing the text\n",
    "data, designing the model architecture, and training and tuning the\n",
    "model.\n",
    "\n",
    "### Addressing Imbalanced Data\n",
    "\n",
    "We noticed that the dataset is imbalanced, with 'ham' messages\n",
    "significantly outnumbering 'spam' messages. This can cause the model to\n",
    "be biased towards the majority class, potentially leading to poor\n",
    "performance for the minority class. However, despite this potential\n",
    "issue, our LSTM model achieved high precision, recall, and F1 Score,\n",
    "indicating effective performance.\n",
    "\n",
    "For models that are affected by class imbalance, strategies such as\n",
    "resampling the data, assigning class weights, or using different\n",
    "evaluation metrics can be applied. However, these strategies were not\n",
    "required in our case as the LSTM model demonstrated high performance\n",
    "despite the class imbalance.\n",
    "\n",
    "In conclusion, both in-context learning with GPT-4 and supervised\n",
    "learning with LSTM have shown to be effective for our text\n",
    "classification task. The choice between these methods will depend on the\n",
    "specific requirements and constraints of your task, such as the\n",
    "availability of labeled data, computational resources, and the\n",
    "importance of model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9011 unique tokens.\n",
      "Shape of data tensor: (5572, 250)\n",
      "Shape of label tensor: (5572, 2)\n",
      "(5014, 250) (5014, 2)\n",
      "(558, 250) (558, 2)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=MAX_NB_WORDS,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "    lower=True,\n",
    ")\n",
    "tokenizer.fit_on_texts(df[\"message\"].values)\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Found %s unique tokens.\" % len(word_index))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df[\"message\"].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print(\"Shape of data tensor:\", X.shape)\n",
    "\n",
    "Y = pd.get_dummies(df[\"label\"]).values\n",
    "print(\"Shape of label tensor:\", Y.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.10, random_state=42\n",
    ")\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "71/71 [==============================] - 27s 362ms/step - loss: 0.2322 - accuracy: 0.9207 - val_loss: 0.0813 - val_accuracy: 0.9741\n",
      "Epoch 2/5\n",
      "71/71 [==============================] - 26s 362ms/step - loss: 0.0340 - accuracy: 0.9898 - val_loss: 0.0739 - val_accuracy: 0.9761\n",
      "Epoch 3/5\n",
      "71/71 [==============================] - 26s 368ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.0730 - val_accuracy: 0.9801\n",
      "Epoch 4/5\n",
      "71/71 [==============================] - 26s 364ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.0675 - val_accuracy: 0.9801\n",
      "Epoch 5/5\n",
      "71/71 [==============================] - 26s 372ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0797 - val_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 55ms/step\n",
      "Precision: 0.97\n",
      "Recall: 0.96\n",
      "F1 Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "Y_test_class = np.argmax(Y_test, axis=1)\n",
    "Y_pred_class = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "precision = precision_score(Y_test_class, Y_pred_class)\n",
    "recall = recall_score(Y_test_class, Y_pred_class)\n",
    "f1 = f1_score(Y_test_class, Y_pred_class)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of Supervised Learning with LSTM\n",
    "\n",
    "The performance of the Long Short-Term Memory (LSTM) model, a type of\n",
    "recurrent neural network, for our SMS spam classification problem was\n",
    "evaluated using three key metrics: precision, recall, and the F1 score.\n",
    "The following table summarizes the obtained results:\n",
    "\n",
    "|      | Precision | Recall | F1 Score |\n",
    "|------|-----------|--------|----------|\n",
    "| LSTM | 0.97      | 0.96   | 0.97     |\n",
    "\n",
    "Here is an interpretation of these results:\n",
    "\n",
    "1. **Precision:** A precision of 0.97 for the LSTM model indicates that when the model predicts a message to be 'spam', it is correct about 97% of the time. This represents a high degree of accuracy in the prediction of spam messages, indicating a minimal rate of 'ham' messages incorrectly classified as 'spam' (false positives).\n",
    "\n",
    "2. **Recall:** A recall value of 0.96 implies that the LSTM model correctly identifies 96% of all actual 'spam' messages. However, it also suggests a 4% rate of 'spam' messages incorrectly classified as 'ham' (false negatives).\n",
    "\n",
    "3. **F1 Score:** The F1 score, which is the harmonic mean of precision and recall, stands at 0.97. This score illustrates a solid balance between precision and recall, showing the model's effectiveness in managing both false positives and false negatives.\n",
    "\n",
    "The LSTM model demonstrates a strong performance for this text\n",
    "classification problem. Despite being a more complex and time-consuming\n",
    "approach compared to in-context learning with GPT-4, the LSTM model\n",
    "presents its own advantages. Particularly, it tends to perform better\n",
    "with larger datasets and when more control over the model's parameters\n",
    "is required. The LSTM model's performance is especially remarkable\n",
    "considering the imbalanced nature of the dataset, emphasizing the\n",
    "robustness of this supervised learning technique."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Comparison of Zero-Shot Learning and Supervised Learning \n",
    "\n",
    "In this study, we utilized the Spam Classification dataset to compare\n",
    "two distinctive approaches for classifying messages as either \"spam\" or\n",
    "\"ham\" (non-spam): zero-shot learning using the GPT-4 model, and\n",
    "supervised learning using a LSTM-based deep learning model.\n",
    "\n",
    "The zero-shot learning approach involves utilizing an AI model,\n",
    "specifically the GPT-4 model, which has not been explicitly trained on\n",
    "the task at hand (spam detection), but leverages its general language\n",
    "understanding abilities to make predictions. On the other hand, the LSTM\n",
    "model is a deep learning model that is trained on a labeled dataset to\n",
    "predict whether a message is spam or not, thus representing a\n",
    "traditional supervised learning approach.\n",
    "\n",
    "We faced a notable challenge in this experiment: the unbalanced\n",
    "distribution of spam and ham messages in the dataset. To address this,\n",
    "we made sure to sample equal numbers of each class when evaluating the\n",
    "performance of the models.\n",
    "\n",
    "We evaluated the performance of the models using three metrics:\n",
    "precision, recall, and F1 score. Each of these metrics provides a\n",
    "different perspective on the model's performance. Precision measures how\n",
    "many of the predicted spam messages were actually spam. Recall, also\n",
    "known as sensitivity, measures how many of the actual spam messages were\n",
    "correctly identified by the model. The F1 score combines precision and\n",
    "recall to provide a single metric that balances both considerations.\n",
    "\n",
    "Here are the final results:\n",
    "\n",
    "| Model Type        | Precision | Recall | F1 Score |\n",
    "|-------------------|-----------|--------|----------|\n",
    "| GPT-4 (Zero-Shot) | 0.92      | 0.97   | 0.95     |\n",
    "| LSTM              | 0.97      | 0.96   | 0.97     |\n",
    "\n",
    "While both models performed quite well, the LSTM model demonstrated a\n",
    "slightly superior performance in terms of precision and F1 score. This\n",
    "result highlights the value of targeted, supervised learning for tasks\n",
    "such as spam detection. However, it is noteworthy that the GPT-4 model\n",
    "performed remarkably well even without any explicit training on this\n",
    "specific task, underscoring the power of zero-shot learning and the\n",
    "versatility of advanced language models like GPT-4.\n",
    "\n",
    "This comparison sheds light on the potential of both traditional\n",
    "supervised learning models and more recent zero-shot learning techniques\n",
    "in text classification tasks. The choice between these approaches\n",
    "depends on several factors, including the availability of labeled data,\n",
    "computational resources, and the specific requirements of the task at\n",
    "hand.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot In-Context Learning with GPT-4\n",
    "\n",
    "In the previous sections, we explored both zero-shot in-context learning\n",
    "with GPT-4 and a supervised learning approach using an LSTM model for\n",
    "our SMS spam classification problem. However, another learning paradigm\n",
    "exists that combines elements from both: few-shot learning. This method\n",
    "aims to make predictions after seeing only a handful of examples, hence\n",
    "its name. \n",
    "\n",
    "In the case of the GPT-4 model, it refers to in-context learning, where\n",
    "the model makes predictions based on the conversation history provided,\n",
    "with a small set of examples included as part of the context. The\n",
    "structure of these examples, or 'shots', plays a crucial role in guiding\n",
    "the model to produce the desired output. These 'shots' could be seen as\n",
    "miniature lessons that teach the model how to perform a task without\n",
    "explicitly programming it.\n",
    "\n",
    "In the context of our SMS spam classification problem, the general\n",
    "structure of a prompt for few-shot learning would look like this:\n",
    "\n",
    "```text\n",
    "    prompt = (\n",
    "        \"I am a model trained to identify spam and non-spam emails. Here are some examples of my training:\\n\"\n",
    "        \"Example 1:\\n\"\n",
    "        \"Question: Given the following email content, is the email spam or ham?\\n\"\n",
    "        \"Email Content: 'You have won a lottery! Claim your prize now.'\\n\"\n",
    "        \"Answer: Spam\\n\"\n",
    "        \"...\\n\"\n",
    "        \"Now, a new example to classify:\\n\"\n",
    "        \"Question: Given the following email content, is the email spam or ham?\\n\"\n",
    "        f\"Email Content: {msg}\\n\"\n",
    "    )\n",
    "```\n",
    "\n",
    "Similar to zero-shot learning, the model has never seen the specific\n",
    "task before during its training. However, unlike zero-shot learning, it\n",
    "is provided with a few examples of the task in the conversation history.\n",
    "This way, the model learns from these examples to make accurate\n",
    "predictions for the new instances.\n",
    "\n",
    "It's important to note that our dataset is unbalanced, with the 'ham'\n",
    "messages outnumbering the 'spam' messages. The proportion of each class,\n",
    "as mentioned before, is approximately 87% 'ham' and 13% 'spam'. When\n",
    "creating our random sample for few-shot learning, we'll need to keep\n",
    "this class imbalance in mind. While our previous approach addressed this\n",
    "issue by creating a balanced sample, few-shot learning might behave\n",
    "differently, and we may need to adjust our approach accordingly. We will\n",
    "explore the results and address any imbalance issues as needed.\n",
    "\n",
    "As in the previous sections, we will be using precision, recall, and F1\n",
    "score to assess the performance of few-shot in-context learning.\n",
    "However, just like in zero-shot learning, AUC isn't applicable due to\n",
    "the inherent nature of the GPT-4 model. The following sections will dive\n",
    "deeper into the implementation and results of few-shot in-context\n",
    "learning with GPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: K, my roommate also wants a dubsack and another friend may also want some so plan on bringing extra, I'll tell you when they know for sure\n",
      "Response: Answer: ham\n",
      "Message: FRAN I DECIDED 2 GO N E WAY IM COMPLETELY BROKE AN KNACKERED I GOT UP BOUT 3 C U 2MRW LOVE JANX P.S THIS IS MY DADS FONE, -NO CREDIT\n",
      "Response: Answer: ham\n",
      "Message: Oh k.i think most of wi and nz players unsold.\n",
      "Response: Answer: ham\n",
      "Message: Lolnice. I went from a fish to ..water.?\n",
      "Response: Answer: ham\n",
      "Message: Just sent it. So what type of food do you like?\n",
      "Response: Answer: ham\n",
      "Message: K, I might come by tonight then if my class lets out early\n",
      "Response: Answer: ham\n",
      "Message: Mark works tomorrow. He gets out at 5. His work is by your house so he can meet u afterwards.\n",
      "Response: Answer: ham\n",
      "Message: Baaaaabe! I misss youuuuu ! Where are you ? I have to go and teach my class at 5 ...\n",
      "Response: Answer: ham\n",
      "Message: somewhere out there beneath the pale moon light someone think in of u some where out there where dreams come true... goodnite &amp; sweet dreams\n",
      "Response: Answer: ham\n",
      "Message: Bull. Your plan was to go floating off to IKEA with me without a care in the world. So i have to live with your mess another day.\n",
      "Response: Answer: ham\n",
      "Message: So your telling me I coulda been your real Valentine and I wasn't? U never pick me for NOTHING!!\n",
      "Response: Answer: ham\n",
      "Message: PLEASSSSSSSEEEEEE TEL ME V AVENT DONE SPORTSx\n",
      "Response: Answer: ham\n",
      "Message: Y de asking like this.\n",
      "Response: Answer: ham\n",
      "Message: I'm on my way home. Went to change batt 4 my watch then go shop a bit lor.\n",
      "Response: Answer: ham\n",
      "Message: Should i buy him a blackberry bold 2 or torch. Should i buy him new or used. Let me know. Plus are you saying i should buy the  &lt;#&gt; g wifi ipad. And what are you saying about the about the  &lt;#&gt; g?\n",
      "Response: Answer: ham\n",
      "Message: Sir, good morning. Hope you had a good weekend. I called to let you know that i was able to raise  &lt;#&gt;  from my dad. He however said he would make the rest available by mid feb. This amount is still quite short and i was hoping you would help. Do have a good day. Abiola\n",
      "Response: Answer: ham\n",
      "Message: So anyways, you can just go to your gym or whatever, my love *smiles* I hope your ok and having a good day babe ... I miss you so much already\n",
      "Response: Answer: ham\n",
      "Message: I can't, I don't have her number!\n",
      "Response: Answer: ham\n",
      "Message: I want  &lt;#&gt;  rs da:)do you have it?\n",
      "Response: Answer: ham\n",
      "Message: Gain the rights of a wife.dont demand it.i am trying as husband too.Lets see\n",
      "Response: Answer: ham\n",
      "Message: I'm stuck in da middle of da row on da right hand side of da lt... \n",
      "Response: Answer: ham\n",
      "Message: Is avatar supposed to have subtoitles\n",
      "Response: Answer: ham\n",
      "Message: All sounds good. Fingers . Makes it difficult to type\n",
      "Response: Answer: ham\n",
      "Message: Ok lor... But buy wat?\n",
      "Response: Answer: ham\n",
      "Message: These won't do. Have to move on to morphine\n",
      "Response: Answer: ham\n",
      "Message: awesome, how do I deal with the gate? Charles told me last night but, uh, yeah\n",
      "Response: Answer: ham\n",
      "Message: Also fuck you and your family for going to rhode island or wherever the fuck and leaving me all alone the week I have a new bong &gt;:(\n",
      "Response: Answer: ham\n",
      "Message: I'm on the bus. Love you\n",
      "Response: Answer: ham\n",
      "Message: Will be office around 4 pm. Now i am going hospital.\n",
      "Response: Answer: ham\n",
      "Message: I'm home.\n",
      "Response: Answer: ham\n",
      "Message: I will lick up every drop :) are you ready to use your mouth as well?\n",
      "Response: Answer: ham\n",
      "Message: My supervisor find 4 me one lor i thk his students. I havent ask her yet. Tell u aft i ask her.\n",
      "Response: Answer: ham\n",
      "Message: Dai i downloaded but there is only exe file which i can only run that exe after installing.\n",
      "Response: Answer: ham\n",
      "Message: That sucks. I'll go over so u can do my hair. You'll do it free right?\n",
      "Response: Answer: ham\n",
      "Message: Printer is cool. I mean groovy. Wine is groovying\n",
      "Response: Answer: ham\n",
      "Message: I have gone into get info bt dont know what to do\n",
      "Response: Answer: ham\n",
      "Message: Rightio. 11.48 it is then. Well arent we all up bright and early this morning.\n",
      "Response: Answer: ham\n",
      "Message: 1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cancer. 1Lemon/Day=No Fat. 1Cup Milk/day=No Bone Problms 3 Litres Watr/Day=No Diseases Snd ths 2 Whom U Care..:-)\n",
      "Response: Answer: ham\n",
      "Message: I just saw ron burgundy captaining a party boat so yeah\n",
      "Response: Answer: ham\n",
      "Message: Night night, see you tomorrow\n",
      "Response: Answer: ham\n",
      "Message: Please leave this topic..sorry for telling that..\n",
      "Response: Answer: ham\n",
      "Message: Idea will soon get converted to live:)\n",
      "Response: Answer: ham\n",
      "Message: Am only searching for good dual sim mobile pa.\n",
      "Response: Answer: ham\n",
      "Message: Don't Think About \"What u Have Got\" Think About \"How to Use It That You Have Got\" gooD ni8\n",
      "Response: Answer: ham\n",
      "Message: Did u download the fring app?\n",
      "Response: Answer: ham\n",
      "Message: Its a great day. Do have yourself a beautiful one.\n",
      "Response: Answer: ham\n",
      "Message: Its too late:)but its k.wish you the same.\n",
      "Response: Answer: ham\n",
      "Message: And stop wondering \"wow is she ever going to stop tm'ing me ?!\" because I will tm you whenever I want because you are MINE ... *laughs*\n",
      "Response: Answer: ham\n",
      "Message: Quite lor. But dun tell him wait he get complacent...\n",
      "Response: Answer: ham\n",
      "Message: Hiya, sorry didn't hav signal. I haven't seen or heard from and neither has, which is unusual in itself! I'll put on the case and get him to sort it out! Hugs and snogs.\n",
      "Response: Answer: ham\n",
      "Message: Nothing just getting msgs by dis name wit different no's..\n",
      "Response: Answer: ham\n",
      "Message: Yeh. Indians was nice. Tho it did kane me off a bit he he. We shud go out 4 a drink sometime soon. Mite hav 2 go 2 da works 4 a laugh soon. Love Pete x x\n",
      "Response: Answer: ham\n",
      "Message: Pls speak with me. I wont ask anything other then you friendship.\n",
      "Response: Answer: ham\n",
      "Message: Tell rob to mack his gf in the theater\n",
      "Response: Answer: ham\n",
      "Message: Dunno lei shd b driving lor cos i go sch 1 hr oni.\n",
      "Response: Answer: ham\n",
      "Message: Man this bus is so so so slow. I think you're gonna get there before me\n",
      "Response: Answer: ham\n",
      "Message: Thank you. And by the way, I just lost.\n",
      "Response: Answer: ham\n",
      "Message: Which is why i never wanted to tell you any of this. Which is why i'm so short with you and on-edge as of late.\n",
      "Response: Answer: ham\n",
      "Message: Why de. You looking good only:-)..\n",
      "Response: Answer: ham\n",
      "Message: Its ok., i just askd did u knw tht no?\n",
      "Response: Answer: ham\n",
      "Message: I want to sent  &lt;#&gt; mesages today. Thats y. Sorry if i hurts\n",
      "Response: Answer: ham\n",
      "Message: What your plan for pongal?\n",
      "Response: Answer: ham\n",
      "Message: K.:)you are the only girl waiting in reception ah?\n",
      "Response: Answer: ham\n",
      "Message: Lul im gettin some juicy gossip at the hospital. Two nurses are talking about how fat they are gettin. And one thinks shes obese. Oyea.\n",
      "Response: Answer: ham\n",
      "Message: Dude ive been seeing a lotta corvettes lately\n",
      "Response: Answer: ham\n",
      "Message: Boo. How's things? I'm back at home and a little bored already :-(\n",
      "Response: Answer: ham\n",
      "Message: That's cool he'll be here all night, lemme know when you're around\n",
      "Response: Answer: ham\n",
      "Message: SORRY IM STIL FUCKED AFTER LAST NITE WENT TOBED AT 430 GOT UP 4 WORK AT 630\n",
      "Response: Answer: ham\n",
      "Message: Lol I know! Hey someone did a great inpersonation of flea on the forums. I love it!\n",
      "Response: Answer: ham\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for 10KTPM-200RPM in organization org-e65yKoVCQyCbjVZoGsVdo8mQ on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 48\u001b[0m\n\u001b[1;32m     42\u001b[0m prompt \u001b[39m=\u001b[39m (\n\u001b[1;32m     43\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mQuestion: Given the following email content, is the email spam or ham?\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEmail Content: \u001b[39m\u001b[39m{\u001b[39;00mrow[\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m example_prompts\u001b[39m.\u001b[39mappend({\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: prompt})\n\u001b[0;32m---> 48\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     49\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-4\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     50\u001b[0m     messages\u001b[39m=\u001b[39;49mexample_prompts,\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMessage: \u001b[39m\u001b[39m{\u001b[39;00mrow[\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m response \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/esg-lab/env/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Projects/esg-lab/env/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Projects/esg-lab/env/lib/python3.11/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Projects/esg-lab/env/lib/python3.11/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    629\u001b[0m         ),\n\u001b[1;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/esg-lab/env/lib/python3.11/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for 10KTPM-200RPM in organization org-e65yKoVCQyCbjVZoGsVdo8mQ on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"SMSSpamCollection\", sep=\"\\t\", names=[\"label\", \"message\"])\n",
    "\n",
    "# Get 10 random examples\n",
    "examples = df.sample(10)\n",
    "\n",
    "# Set up examples\n",
    "example_prompts = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant capable of identifying spam emails.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for _, row in examples.iterrows():\n",
    "    example_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Question: Given the following email content, is the email spam or ham?\\n\"\n",
    "            f\"Email Content: {row['message']}\\n\"\n",
    "            f\"Answer: {row['label']}\"\n",
    "        ),\n",
    "    }\n",
    "    example_prompts.append(example_prompt)\n",
    "\n",
    "# Get 200 random samples, ensuring balance between classes\n",
    "ham_samples = df[df[\"label\"] == \"ham\"].sample(100)\n",
    "spam_samples = df[df[\"label\"] == \"spam\"].sample(100)\n",
    "samples = pd.concat([ham_samples, spam_samples])\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "for _, row in samples.iterrows():\n",
    "    prompt = (\n",
    "        \"Question: Given the following email content, is the email spam or ham?\\n\"\n",
    "        f\"Email Content: {row['message']}\"\n",
    "    )\n",
    "    example_prompts.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=example_prompts,\n",
    "    )\n",
    "\n",
    "    print(f\"Message: {row['message']}\")\n",
    "    response = completion.choices[0].message[\"content\"]\n",
    "    print(\"Response:\", response)\n",
    "    predicted_label = \"spam\" if \"A\" in response else \"ham\"\n",
    "    correct_predictions += int(predicted_label == row[\"label\"])\n",
    "    time.sleep(12)  # sleep 1 second between API requests\n",
    "\n",
    "accuracy = correct_predictions / len(samples)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://help.openai.com/en/articles/6897202-ratelimiterror"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
